# -*- coding: utf-8 -*-
"""Final _AA 7015

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16M2Dma-YIvEu6Y7WzUJw1Yc22JoWBzRf
"""

#mount drive
from google.colab import drive
drive.mount('/content/drive')

#Libraries (numpy and pandas)
import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
#logistics regression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
#random forest
from sklearn.ensemble import RandomForestClassifier
#MLP
from sklearn.neural_network import MLPClassifier

# to remove the error output for better view
import warnings
warnings.filterwarnings("ignore")

"""Data Preprocessing"""

#Load Datasets
file_path = '/content/drive/My Drive/heart.csv'
df=pd.read_csv(file_path)
#df.head()
df

#Feature Processing - One-Hot Encoding
df['Sex'] = pd.get_dummies(df['Sex'], drop_first=True, dtype=int)

features = pd.get_dummies(df['ChestPainType'], prefix='ChestPainType')
df = pd.concat([df, features], axis=1)
df = df.drop(['ChestPainType'], axis=1)

features = pd.get_dummies(df['RestingECG'], prefix='RestingECG')
df = pd.concat([df, features], axis=1)
df = df.drop(['RestingECG'], axis=1)

features = pd.get_dummies(df['ExerciseAngina'], prefix='ExerciseAngina')
df = pd.concat([df, features], axis=1)
df = df.drop(['ExerciseAngina'], axis=1)

features = pd.get_dummies(df['ST_Slope'], prefix='ST_Slope')
df = pd.concat([df, features], axis=1)
df = df.drop(['ST_Slope'], axis=1)

#Load the data after transform
display(df)

# Specify the feature with missing values
feature_with_missing_values = 'Cholesterol'

# Calculate mean and standard deviation for the feature
mean = np.mean(df[feature_with_missing_values])
std_dev = np.std(df[feature_with_missing_values])

# Calculate z-scores for the feature
df['z_score'] = (df[feature_with_missing_values] - mean) / std_dev

# Define outlier threshold
threshold = 3

# Handle missing values by imputing with the mean of non-outlier values
non_outliers = df[np.abs(df['z_score']) <= threshold]
mean_non_outliers = np.mean(non_outliers[feature_with_missing_values])

# Impute missing values and outliers
df[feature_with_missing_values] = df[feature_with_missing_values].fillna(mean_non_outliers)
df.loc[np.abs(df['z_score']) > threshold, feature_with_missing_values] = mean_non_outliers

# Drop the z_score column as it's no longer needed
df = df.drop(columns=['z_score'])

# Define your target variable and features
target = 'HeartDisease'
features = df.drop(columns=[target])

# Convert categorical features to numerical using one-hot encoding
features = pd.get_dummies(features)

# Define age group bins and labels
bins = [0, 20, 30, 40, 50, 60, 70, float('inf')]
labels = ['0-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71+']

# Create a new 'AgeGroup' column based on the bins and labels
df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)

# Display the DataFrame with the new 'AgeGroup' column
display(df)

"""Split datasets"""

# Split the data into training (70%), validation (20%), and test sets (10%)
X_train, X_temp, y_train, y_temp = train_test_split(features, df[target], test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.3333, random_state=42)

"""Logistics Regression (Sigmoid) -- Baseline"""

#Sigmoid Function
def sigmoid(z):
  z = np.array(z, dtype=np.float64)
  return 1/(1+np.exp(-z))


#Logistic Regression class
class LogisticRegression:
    def __init__(self, lr=0.1, n_iter=2000):
        self.lr = lr
        self.n_iter = n_iter
        self.weights = None
        self.bias = None

    def fit(self, X, y):

        X = X.to_numpy().astype(np.float64)
        y = y.to_numpy()
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0

        for _ in range(self.n_iter):
            linear_pred = np.dot(X, self.weights) + self.bias
            predictions = sigmoid(linear_pred)

            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))
            db = (1 / n_samples) * np.sum(predictions - y)

            self.weights -= self.lr * dw
            self.bias -= self.lr * db

    def predict(self, X):
        linear_pred = np.dot(X, self.weights) + self.bias
        y_pred_log_reg = sigmoid(linear_pred)
        class_pred = [0 if y <= 0.5 else 1 for y in y_pred_log_reg]
        return class_pred

    def predict_proba(self, X):
        X = X.to_numpy().astype(np.float64)
        linear_pred = np.dot(X, self.weights) + self.bias
        return sigmoid(linear_pred)

# Initialize and train the logistic regression model
log_reg_model = LogisticRegression(lr=0.1, n_iter=2000)
log_reg_model.fit(X_train, y_train)

# Make predictions on the training set to calculate training accuracy
y_train_pred_log_reg = log_reg_model.predict(X_train)
train_accuracy_log_reg = accuracy_score(y_train, y_train_pred_log_reg)
test_report_log_reg = classification_report(y_train, y_train_pred_log_reg)
print(f"Training Accuracy: {train_accuracy_log_reg}")
print("Training Classification Report:\n", test_report_log_reg)

# Make predictions on the validation set
y_val_pred_log_reg = log_reg_model.predict(X_val)

# Evaluate the model on the validation set
val_accuracy_log_reg = accuracy_score(y_val, y_val_pred_log_reg)
val_report_log_reg = classification_report(y_val, y_val_pred_log_reg)

print(f"Validation Accuracy: {val_accuracy_log_reg}")
print("Validation Classification Report:\n", val_report_log_reg)

# Make predictions on the test set
y_test_pred_log_reg = log_reg_model.predict(X_test)

# Evaluate the model on the test set
test_accuracy_log_reg = accuracy_score(y_test, y_test_pred_log_reg)
test_report_log_reg = classification_report(y_test, y_test_pred_log_reg)

print(f"Test Accuracy: {test_accuracy_log_reg}")
print("Test Classification Report:\n", test_report_log_reg)

"""Random Forest Algorithm"""

#Random Forest Algorithm (Fine Tune)

# Initialize and train the Random Forest classifier
rf_model = RandomForestClassifier(n_estimators=100, max_samples=0.8, max_depth=10,random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions on the training set to calculate training accuracy
y_train_pred_rf = rf_model.predict(X_train)
train_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)
test_report_rf= classification_report(y_train, y_train_pred_rf)
print(f"Training Accuracy: {train_accuracy_rf}")
print("Training Classification Report:\n", test_report_rf)

# Make predictions on the validation set
y_val_pred_rf = rf_model.predict(X_val)

# Evaluate the model on the validation set
val_accuracy_rf = accuracy_score(y_val, y_val_pred_rf)
val_report_rf = classification_report(y_val, y_val_pred_rf)

print(f"Validation Accuracy: {val_accuracy_rf}")
print("Validation Classification Report:\n", val_report_rf)

# Make predictions on the test set
y_test_pred_rf = rf_model.predict(X_test)

# Evaluate the model on the test set
test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)
test_report_rf = classification_report(y_test, y_test_pred_rf)

print(f"Test Accuracy: {test_accuracy_rf}")
print("Test Classification Report:\n", test_report_rf)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the confusion matrix
cm_rf = confusion_matrix(y_test, y_test_pred_rf)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title('Confusion Matrix for Random Forest')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""Multi-Layer Perceptron (MLP)"""

# MLP Classifier (Fine tune)
MLP_model = MLPClassifier(hidden_layer_sizes=(256, 128, 64,), activation='relu', batch_size = 64, max_iter=1000, random_state=42)
MLP_model.fit(X_train, y_train)

# Make predictions on the training set to calculate training accuracy
y_train_pred_MLP = MLP_model.predict(X_train)
train_accuracy_MLP = accuracy_score(y_train, y_train_pred_MLP)
test_report_MLP = classification_report(y_train, y_train_pred_MLP)
print(f"Training Accuracy: {train_accuracy_MLP}")
print("Training Classification Report:\n", test_report_MLP)

# Make predictions on the validation set
y_val_pred_MLP = MLP_model.predict(X_val)

# Evaluate the model on the validation set
val_accuracy_MLP = accuracy_score(y_val, y_val_pred_MLP)
val_report_MLP = classification_report(y_val, y_val_pred_MLP)

print(f"Validation Accuracy: {val_accuracy_MLP}")
print("Validation Classification Report:\n", val_report_MLP)

# Make predictions on the test set
y_test_pred_MLP = MLP_model.predict(X_test)

# Evaluate the model on the test set
test_accuracy_MLP = accuracy_score(y_test, y_test_pred_MLP)
test_report_MLP = classification_report(y_test, y_test_pred_MLP)

print(f"Test Accuracy: {test_accuracy_MLP}")
print("Test Classification Report:\n", test_report_MLP)

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Calculate the confusion matrix
cm_MLP = confusion_matrix(y_test, y_test_pred_MLP)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(8, 6))
sns.heatmap(cm_MLP, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title('Confusion Matrix for MLP')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()